{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Step 0: Required Libraries -----------\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.ops import box_iou\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----------- Step 1: Custom Dataset Loader -----------\n",
    "\n",
    "class FLIRDataset(Dataset):\n",
    "    def __init__(self, img_dir, annot_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.annot_dir = annot_dir\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(img_dir) if f.endswith('.jpeg') or f.endswith('.jpg')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        annot_path = os.path.join(self.annot_dir, self.images[idx].replace('.jpeg', '.xml'))\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        boxes, labels = self.parse_annotation(annot_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        target = {\"boxes\": torch.tensor(boxes, dtype=torch.float32),\n",
    "                  \"labels\": torch.tensor(labels, dtype=torch.int64)}\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def parse_annotation(self, xml_file):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        label_map = {'person': 1, 'vehicle': 2}  # Label encoding\n",
    "\n",
    "        for obj in root.findall('object'):\n",
    "            label = obj.find('name').text\n",
    "            if label not in label_map:\n",
    "                continue\n",
    "            bbox = obj.find('bndbox')\n",
    "            xmin = float(bbox.find('xmin').text)\n",
    "            ymin = float(bbox.find('ymin').text)\n",
    "            xmax = float(bbox.find('xmax').text)\n",
    "            ymax = float(bbox.find('ymax').text)\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "            labels.append(label_map[label])\n",
    "        return boxes, labels\n",
    "\n",
    "# ----------- Step 2: Model (Simple CNN + Detection Head) -----------\n",
    "\n",
    "class SimpleDetector(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(SimpleDetector, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1), nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(128, num_classes, 1)\n",
    "        )\n",
    "\n",
    "        self.reg_head = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(128, 4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.feature_extractor(x)\n",
    "        cls_logits = self.cls_head(feat)\n",
    "        bbox_preds = self.reg_head(feat)\n",
    "        return cls_logits, bbox_preds\n",
    "\n",
    "# ----------- Step 3: Loss Functions -----------\n",
    "\n",
    "def detection_loss(cls_logits, bbox_preds, targets):\n",
    "    cls_loss_fn = nn.CrossEntropyLoss()\n",
    "    reg_loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "    # Dummy loss (for demonstration)\n",
    "    cls_loss = cls_loss_fn(cls_logits.mean([2,3]), targets[\"labels\"])  # Simplified\n",
    "    reg_loss = reg_loss_fn(bbox_preds.mean([2,3]), targets[\"boxes\"].float())  # Simplified\n",
    "\n",
    "    return cls_loss + reg_loss\n",
    "\n",
    "# ----------- Step 4: Training -----------\n",
    "\n",
    "def train(model, dataloader, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for images, targets in tqdm(dataloader):\n",
    "            images = images.cuda()\n",
    "            targets = {k: v.cuda() for k, v in targets.items()}\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            cls_logits, bbox_preds = model(images)\n",
    "            loss = detection_loss(cls_logits, bbox_preds, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# ----------- Step 5: Evaluation -----------\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(dataloader):\n",
    "            images = images.cuda()\n",
    "            cls_logits, bbox_preds = model(images)\n",
    "            # You can expand this into full mAP calculation\n",
    "            print(\"Sample Predictions:\", cls_logits.mean().item(), bbox_preds.mean().item())\n",
    "\n",
    "# ----------- Step 6: Pipeline -----------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Dataset paths\n",
    "    train_img_dir = \"/path_to/FLIR/train/images\"\n",
    "    train_annot_dir = \"/path_to/FLIR/train/annotations\"\n",
    "\n",
    "    val_img_dir = \"/path_to/FLIR/val/images\"\n",
    "    val_annot_dir = \"/path_to/FLIR/val/annotations\"\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_dataset = FLIRDataset(train_img_dir, train_annot_dir, transform=transform)\n",
    "    val_dataset = FLIRDataset(val_img_dir, val_annot_dir, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "    # Model\n",
    "    model = SimpleDetector(num_classes=3).cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    # Train\n",
    "    train(model, train_loader, optimizer, epochs=10)\n",
    "\n",
    "    # Evaluate\n",
    "    evaluate(model, val_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
